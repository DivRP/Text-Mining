{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding='utf-8', errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfnonpro = data2df('HealthProNonPro/NonPro/', 0) # NEG- Answer not as good as professional advice\n",
    "dfpro = data2df('HealthProNonPro/Pro/', 1) # POS- Answer as good as professional advice\n",
    "\n",
    "df = pd.concat([dfpro, dfnonpro], axis=0)\n",
    "#df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup the data for Training/Testing. Use 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df['text'], df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use Spacy to preprocess the data. Explore and pick appropriate preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Applications/anaconda3/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (1.17.2)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.7/site-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Applications/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.36.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Applications/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Applications/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /Applications/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Applications/anaconda3/lib/python3.7/site-packages (from en_core_web_md==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.17.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (41.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Applications/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Applications/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_md==2.2.5) (4.36.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Applications/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Applications/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /Applications/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "    tokens = [token.lemma_.lower()\n",
    "             for token in doc\n",
    "             if(\n",
    "             not token.is_punct and\n",
    "             not token.is_space and\n",
    "             not token.is_stop)]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 2.81 s, total: 51.5 s\n",
      "Wall time: 41.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    carotid artery disease cause build plaque insi...\n",
       "1                                          baking soda\n",
       "2                      course break think u break bone\n",
       "3    antibiotic start show result 24 48 hour take d...\n",
       "4    male equivalent yeast infection pass forth giv...\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(list(Xtrain))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtrain = pd.Series(clean_corpus)\n",
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Setup a Pipeline with TfidfVectorizer and Naïve Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('tfidf',TfidfVectorizer(encoding=\"utf-8\",lowercase=True,ngram_range=(1,1),\n",
    "                             use_idf=True, smooth_idf=True,sublinear_tf=False,\n",
    "                            vocabulary=None)),\n",
    "    (\"clf\",MultinomialNB(alpha=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7939972714870396\n",
      "[[344  14]\n",
      " [137 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82       358\n",
      "           1       0.94      0.63      0.76       375\n",
      "\n",
      "    accuracy                           0.79       733\n",
      "   macro avg       0.83      0.80      0.79       733\n",
      "weighted avg       0.83      0.79      0.79       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = pipeline.fit(Xtrain,ytrain)\n",
    "ypred = pipeline.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Grid Search with 4-fold Cross Validation to search for the best values for the following two hyper-parameters \n",
    "#### a. sublinear_tf in TfidfVectorizer\n",
    "#### b. alpha in Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {'tfidf__sublinear_tf': (True,False), \n",
    "               'clf__alpha': (0.1,0.25,0.5,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sr = GridSearchCV(estimator=pipeline,param_grid=grid_params,cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                        sublinear_tf=False,\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('clf',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__alpha': (0.1, 0.25, 0.5, 1),\n",
       "                         'tfidf__sublinear_tf': (True, False)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sr.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tPrint Evaluation metrics using the Best Estimator resulting from the Grid Search for Prediction/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__alpha': 0.1, 'tfidf__sublinear_tf': False}\n",
      "0.9392076502732241\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_sr.best_params_\n",
    "print(best_parameters)\n",
    "print(grid_sr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nlp.pipe(list(Xtest))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtest = pd.Series(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9345156889495225\n",
      "[[319  39]\n",
      " [  9 366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       358\n",
      "           1       0.90      0.98      0.94       375\n",
      "\n",
      "    accuracy                           0.93       733\n",
      "   macro avg       0.94      0.93      0.93       733\n",
      "weighted avg       0.94      0.93      0.93       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred1 = grid_sr.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred1))\n",
    "print (metrics.confusion_matrix(ytest, ypred1))\n",
    "print (metrics.classification_report(ytest, ypred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\tExtract the true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = metrics.confusion_matrix(y_true=ytest, y_pred=ypred1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9345156889495225\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for 1: 0.9037037037037037\n",
      "Precision for 0: 0.9725609756097561\n"
     ]
    }
   ],
   "source": [
    "precision_1 = TP/(TP+FP)\n",
    "precision_0 = TN/(TN+FN)\n",
    "print(\"Precision for 1:\",precision_1)\n",
    "print(\"Precision for 0:\",precision_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for 1: 0.976\n",
      "Recall for 0: 0.8910614525139665\n"
     ]
    }
   ],
   "source": [
    "recall_1 = TP/(TP+FN)\n",
    "recall_0 = TN/(TN+FP)\n",
    "print(\"Recall for 1:\", recall_1)\n",
    "print(\"Recall for 0:\",recall_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for 1: 0.9384615384615385\n",
      "f1 score for 0: 0.9300291545189504\n"
     ]
    }
   ],
   "source": [
    "f1_score_1 = (2*recall_1*precision_1)/(recall_1+precision_1)\n",
    "f1_score_0 = (2*recall_0*precision_0)/(recall_0+precision_0)\n",
    "print(\"f1 score for 1:\",f1_score_1)\n",
    "print(\"f1 score for 0:\",f1_score_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
